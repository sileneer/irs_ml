{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Word Segmentation\n",
    "Using tokenizer, padding and binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "# import keras_tuner as kt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras. preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    data\n",
      "0                   時間　：\n",
      "1  三月　十日　（　星期四　）　上午　十時　。\n",
      "2                   地點　：\n",
      "3      學術　活動　中心　一樓　簡報室　。\n",
      "4                   主講　：\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./datasets/chinese_word_segmentation/as_training.utf8\", names=['data'])\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train = train[:int(len(train)*0.1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               時間：\n",
      "1    三月十日（星期四）上午十時。\n",
      "2               地點：\n",
      "3      學術活動中心一樓簡報室。\n",
      "4               主講：\n",
      "Name: data, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "0                     時間　：\n",
      "1    三月　十日　（　星期四　）　上午　十時　。\n",
      "2                     地點　：\n",
      "3        學術　活動　中心　一樓　簡報室　。\n",
      "4                     主講　：\n",
      "Name: data, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y = train['data'].copy()\n",
    "X = train['data'].str.replace('\\u3000', '')\n",
    "print(X.head())\n",
    "print(type(X))\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(data):\n",
    "    label = []\n",
    "    index = 0\n",
    "\n",
    "    while index < len(data) - 1:\n",
    "        if data[index + 1] == '\\u3000':\n",
    "            label.append(1)\n",
    "            index += 2\n",
    "        else:\n",
    "            label.append(0)\n",
    "            index += 1\n",
    "            \n",
    "    if index == len(data) - 1:\n",
    "        label.append(1)\n",
    "    return label\n",
    "\n",
    "y = y.apply(create_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                [0, 1, 1]\n",
      "1               [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n",
      "2                                                [0, 1, 1]\n",
      "3                     [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1]\n",
      "4                                                [0, 1, 1]\n",
      "                               ...                        \n",
      "70890                                      [0, 1, 0, 1, 1]\n",
      "70891    [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, ...\n",
      "70892    [1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, ...\n",
      "70893        [0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n",
      "70894           [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1]\n",
      "Name: data, Length: 70895, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<OOV>', split='\\u3000', char_level=True)\n",
    "tokenizer.fit_on_texts(train['data'])\n",
    "char_index = tokenizer.word_index\n",
    "total_chars = len(json.loads(tokenizer.get_config()['word_counts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<OOV>', '\\u3000', '，', '的', '。', '是', '一', '人', '不', '有', '我', '在', '、', '這', '了', '「', '」', '個', '他', '以', '生', '為', '要', '來', '們', '會', '就', '中', '自', '之', '大', '時', '到', '：', '而', '所', '能', '也', '心', '上', '學', '可', '說', '你', '？', '對', '如', '子', '得', '出', '成', '與', '作', '家', '麼', '現', '年', '好', '道', '過', '多', '於', '都', '然', '和', '後', '事', '很', '那', '去', '國', '因', '己', '下', '發', '但', '地', '文', '理', '著', '意', '想', '無', '看', '天', '面', '實', '種', '沒', '方', '當', '經', '同', '只', '用', '力', '十', '此', '本', '定']\n",
      "4396\n"
     ]
    }
   ],
   "source": [
    "print(list(char_index.keys())[:100])\n",
    "print(len(char_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  115  259   97  143\n",
      "  153  695  256  248  152   40 1031   97   32    5]\n",
      "(70895, 164)\n"
     ]
    }
   ],
   "source": [
    "max_length = X.str.len().max() # 188\n",
    "# trunc_type = 'post'\n",
    "padding = 'pre'\n",
    "\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "padded_X = pad_sequences(X_sequences, maxlen=max_length, padding=padding)\n",
    "padded_y = pad_sequences(y, maxlen=max_length, padding=padding)\n",
    "print(padded_X[1])\n",
    "print(padded_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 164)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 164, 64)           281280    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 164, 256)         197632    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 164, 256)         394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 164, 64)           16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 164, 2)            130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 889,730\n",
      "Trainable params: 889,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "\n",
    "xIn = Input(shape=(max_length,))\n",
    "x = Embedding(total_chars, embedding_dim, mask_zero=True, input_length=max_length)(xIn) # mask_zero will ignore timestamps with 0 (aka ignoring the padding)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "# x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "# x = Flatten()(x) don't need to flatten, just put output layer as 2 neurons\n",
    "# x = Dense(64, activation='swish')(x)\n",
    "# x = Dense(64, activation='swish')(x)\n",
    "x = Dense(64, activation='swish')(x)\n",
    "# x = Dense(64, activation='swish')(x)\n",
    "xOut = Dense(2, activation='linear')(x) # softmax is computed by loss function, so don't use activation=\"softmax\" here\n",
    "\n",
    "model = Model(inputs=xIn, outputs=xOut)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSequenceLoss(tf.keras.losses.Loss):\n",
    "    def __init__(\n",
    "        self,\n",
    "        average_across_timesteps=False,\n",
    "        average_across_batch=False,\n",
    "        sum_over_timesteps=True,\n",
    "        sum_over_batch=True,\n",
    "        softmax_loss_function=None,\n",
    "        name=None,\n",
    "        reduction=None, # dummy arg so it can be used as custom object when loading saved model\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.opts = {\n",
    "            \"average_across_timesteps\": average_across_timesteps,\n",
    "            \"average_across_batch\": average_across_batch,\n",
    "            \"sum_over_timesteps\": sum_over_timesteps,\n",
    "            \"sum_over_batch\": sum_over_batch,\n",
    "            \"softmax_loss_function\": softmax_loss_function,\n",
    "            \"name\": name,\n",
    "        }\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        return tfa.seq2seq.sequence_loss(y_pred, y_true,\n",
    "                                         weights=tf.cast(y_pred._keras_mask, tf.float32) if hasattr(y_pred, \"_keras_mask\") else tf.ones(y_true.shape),\n",
    "                                         **self.opts)\n",
    "\n",
    "def binary_crossentropy_arg_names_changed(labels, logits):\n",
    "#     print(labels.numpy(), logits.numpy())\n",
    "    output = tf.nn.sigmoid_cross_entropy_with_logits(tf.cast(labels, tf.float32)[..., tf.newaxis], logits)\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "model.compile(optimizer='adam', loss=MaskedSequenceLoss(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4563 - acc: 0.7691 "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/embedding/embedding_lookup' defined at (most recent call last):\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\asyncio\\base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lzh75\\AppData\\Local\\Temp\\ipykernel_18136\\1591191128.py\", line 12, in <module>\n      history = model.fit(padded_X, padded_y, batch_size=570, epochs=epochs, validation_split=0.2, callbacks=callbacks)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1694, in fit\n      val_logs = self.evaluate(\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in test_step\n      y_pred = self(x, training=False)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding/embedding_lookup'\nindices[275,160] = 4396 is not in [0, 4395)\n\t [[{{node model/embedding/embedding_lookup}}]] [Op:__inference_test_function_36774]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# padded_X = tf.convert_to_tensor(padded_X)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# padded_y = tf.convert_to_tensor(padded_y)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(padded_y))\n\u001B[1;32m---> 12\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpadded_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m570\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdemo_model.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'model/embedding/embedding_lookup' defined at (most recent call last):\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\asyncio\\base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"C:\\coding\\python\\cpython\\python-3.10\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lzh75\\AppData\\Local\\Temp\\ipykernel_18136\\1591191128.py\", line 12, in <module>\n      history = model.fit(padded_X, padded_y, batch_size=570, epochs=epochs, validation_split=0.2, callbacks=callbacks)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1694, in fit\n      val_logs = self.evaluate(\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2040, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1820, in test_function\n      return step_function(self, iterator)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1804, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1792, in run_step\n      outputs = model.test_step(data)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in test_step\n      y_pred = self(x, training=False)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding/embedding_lookup'\nindices[275,160] = 4396 is not in [0, 4395)\n\t [[{{node model/embedding/embedding_lookup}}]] [Op:__inference_test_function_36774]"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "callbacks = [\n",
    "    # tf.keras.callbacks.ModelCheckpoint('./8_best_model', monitor='acc', save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='acc', factor=0.1, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "# padded_X = tf.convert_to_tensor(padded_X)\n",
    "# padded_y = tf.convert_to_tensor(padded_y)\n",
    "print(type(padded_y))\n",
    "history = model.fit(padded_X, padded_y, batch_size=570, epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "model.save(\"demo_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# padded_X = tf.convert_to_tensor(padded_X)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# padded_y = tf.convert_to_tensor(padded_y)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(padded_y))\n\u001B[1;32m---> 12\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpadded_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadded_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m570\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdemo_model.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\keras\\engine\\training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1648\u001B[0m ):\n\u001B[0;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m     args,\n\u001B[0;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1750\u001B[0m     executing_eagerly)\n\u001B[0;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mD:\\coding\\ml\\irs_ml\\irs_ml_venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"8_best_model_weights\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_objects = { \"MaskedSequenceLoss\": MaskedSequenceLoss }\n",
    "# with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "#     model = tf.keras.models.load_model(\"saved-models/bidirectional-lstm/epoch8_valloss0.0042\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predicted results in sentences\n",
    "def segment_sentence(sentence, skip_array):\n",
    "    # assert len(sentence) == len(skip_array)\n",
    "    segmented_sentence = \"\"\n",
    "    for i in range(len(sentence)):\n",
    "        segmented_sentence += sentence[i]\n",
    "        if skip_array[i] == 1:\n",
    "            segmented_sentence += \" \"\n",
    "    return segmented_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"生日快樂\",\n",
    "    \"我的名字是\",\n",
    "    \"今天的天氣很不可思議\",\n",
    "    \"中文單詞\",\n",
    "    \"雪花飄飄北風蕭蕭\",\n",
    "    \"Google 的免費服務可即時在英語和 100 多種其他語言之間翻譯單詞、短語和網頁。\",\n",
    "    \"公教学生是个具有高尚情操、坚韧个性，同时热爱生活，热爱学习，并且愿为人群服务的领袖、双语学者、与彬彬君子。\", # Fail\n",
    "    \"明天更有一場「希望大樹」締造最多雙胞胎集合挑戰金氏世界紀錄活動。\", # OK\n",
    "    \"張玨的這番話讓目前還在台大唸博士班的郭淑珍及她的雙胞胎妹妹郭淑玲感受最深\", # OK except that it splits 張玨\n",
    "    \"然而，就其思想倾向而言，它却是属于日本战后派的，是战后派文学的一个组成部分。\", # Fail. Output: \"然 而 ， 就 其 思 想 倾 向而 言 ， 它 却是 属 于 日 本 战 后 派 的， 是 战 后 派 文 学 的一 个 组成 部分 。 \"\n",
    "    \"如果說電影《遠離賭城》是尼可拉斯凱吉藝術成就上的轉捩點\", # OK except that it doesn't separate 如果說\n",
    "    \"吳宇森正計劃拍攝一部二次大戰的電影《Ｗｉｎｄｔａｌｋｅｒｓ》\", # OK (二次大戰 should not be separated)\n",
    "    \"雄立獅島式是炎黃萬世其無疆\",\n",
    "    \"你好我的名字是傑夫\",\n",
    "    \"不過成員練唱時投入的程度可不輸給一般專業合唱團\",\n",
    "    \"你他媽到底在說我什麼，你這個小婊子？我會讓你知道我畢業於海豹突擊隊班，我曾參與過無數次對基地組織的秘密突襲，並確認殺死了 300 多人。我接受過大猩猩戰爭的訓練，我是整個美國武裝部隊中的頂級狙擊手。你對我來說什麼都不是，只是另一個目標。我會用地球上從未見過的精確度把你他媽擦掉，記住我他媽的話。你認為你可以在互聯網上對我說那些狗屎嗎？再想想，混蛋。在我們說話的時候，我正在聯繫我在美國的秘密間諜網絡，你的 IP 正在被追踪，所以你最好為風暴做好準備，蛆蟲。這場風暴會摧毀你稱之為生命的可悲小東西。你他媽死定了，孩子。我可以在任何地方，任何時間，我可以用七百多種方式殺死你，而這只是我的徒手。我不僅在徒手格斗方面受過廣泛的訓練，而且我還可以使用美國海軍陸戰隊的整個武器庫，我會盡其所能地使用它來將你的悲慘屁股從大陸上抹去，你這個小混蛋。如果你能知道你那小小的“聰明”評論會給你帶來什麼樣的邪惡報應，也許你會忍住你的舌頭。但你不能，你沒有，現在你要付出代價，你這個該死的白痴。我會在你身上發火，你會淹死的。你他媽死定了，孩子。\"[:187],\n",
    "    \"你瞅啥！瞅你咋地！再瞅一个试试！试试就试试！\",\n",
    "]\n",
    "\n",
    "for test_sentence in test_sentences:\n",
    "    test_sentence_sequence = tokenizer.texts_to_sequences([test_sentence])[0]\n",
    "    test_sentence_sequence_padded = pad_sequences([test_sentence_sequence],\n",
    "                                                                                  maxlen=max_length)[0]\n",
    "\n",
    "    actual_pred_start_idx = max_length - len(test_sentence)\n",
    "    test_preds = model.predict(test_sentence_sequence_padded[tf.newaxis, ...])[0, actual_pred_start_idx:]\n",
    "    probabilities = tf.nn.softmax(test_preds)\n",
    "    skip_array = tf.argmax(probabilities, axis=-1)\n",
    "\n",
    "    segment_sentence(test_sentence, skip_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "dtime = dt.time()\n",
    "now = dt.datetime.now()\n",
    "now.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "model.save(f'8_Chinese_Word_Segmentation/8_saved_models/{now}.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6425117d13823fa8044a2c07c859b613f2362d94b282c9a4162ba20339fd2c4d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
