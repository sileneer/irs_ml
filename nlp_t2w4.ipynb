{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Snorkel\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import re\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "# NLP packages\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "import string\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "\n",
    "# punc = string.punctuation\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Supervised learning\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Deep learning libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:55:43.514601Z",
     "end_time": "2023-04-14T02:55:43.602588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-14T01:55:35.116858Z",
     "end_time": "2023-04-14T01:55:37.208799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lzh75\\AppData\\Local\\Temp\\ipykernel_10280\\2854567161.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('datasets/abcnews-date-text.csv', error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1244184 entries, 0 to 1244183\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   text    1244184 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# store the dataset as a Pandas Dataframe\n",
    "df = pd.read_csv('datasets/abcnews-date-text.csv', error_bad_lines=False)\n",
    "#conduct some data cleaning\n",
    "df = df.drop(['publish_date'], axis=1)\n",
    "df = df.rename(columns={'headline_text': 'text'})\n",
    "# df['text'] = df['text'].astype(str)\n",
    "#check the data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                      text\n0        aba decides against community broadcasting lic...\n1           act fire witnesses must be aware of defamation\n2           a g calls for infrastructure protection summit\n3                 air nz staff in aust strike for pay rise\n4            air nz strike to affect australian travellers\n...                                                    ...\n1244179  two aged care residents die as state records 2...\n1244180  victoria records 5;919 new cases and seven deaths\n1244181    wa delays adopting new close contact definition\n1244182  western ringtail possums found badly dehydrate...\n1244183  what makes you a close covid contact here are ...\n\n[1244184 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aba decides against community broadcasting lic...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>act fire witnesses must be aware of defamation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a g calls for infrastructure protection summit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>air nz staff in aust strike for pay rise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>air nz strike to affect australian travellers</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1244179</th>\n      <td>two aged care residents die as state records 2...</td>\n    </tr>\n    <tr>\n      <th>1244180</th>\n      <td>victoria records 5;919 new cases and seven deaths</td>\n    </tr>\n    <tr>\n      <th>1244181</th>\n      <td>wa delays adopting new close contact definition</td>\n    </tr>\n    <tr>\n      <th>1244182</th>\n      <td>western ringtail possums found badly dehydrate...</td>\n    </tr>\n    <tr>\n      <th>1244183</th>\n      <td>what makes you a close covid contact here are ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1244184 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T01:55:37.209797Z",
     "end_time": "2023-04-14T01:55:37.296799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# define constants to represent the class labels :positive, negative, and abstain\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "# define function which looks into the input words to represent a proper label\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# define function which assigns a correct label\n",
    "def make_keyword_lf(keywords, label=POSITIVE):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label))\n",
    "\n",
    "\n",
    "#resource: https://www.snorkel.org/use-cases/01-spam-tutorial#3-writing-more-labeling-functions\n",
    "#these two lists can be further extended\n",
    "\"\"\"positive news might contain the following words' \"\"\"\n",
    "keyword_positive = make_keyword_lf(\n",
    "    keywords=['boosts', 'great', 'develops', 'promising', 'ambitious', 'delighted', 'record', 'win', 'breakthrough',\n",
    "              'recover', 'achievement', 'peace', 'party', 'hope', 'flourish', 'respect', 'partnership', 'champion',\n",
    "              'positive', 'happy', 'bright', 'confident', 'encouraged', 'perfect', 'complete', 'assured'])\n",
    "\"\"\"negative news might contain the following words\"\"\"\n",
    "keyword_negative = make_keyword_lf(\n",
    "    keywords=['war', 'solidiers', 'turmoil', 'injur', 'trouble', 'aggressive', 'killed', 'coup', 'evasion', 'strike',\n",
    "              'troops', 'dismisses', 'attacks', 'defeat', 'damage', 'dishonest', 'dead', 'fear', 'foul', 'fails',\n",
    "              'hostile', 'cuts', 'accusations', 'victims', 'death', 'unrest', 'fraud', 'dispute', 'destruction',\n",
    "              'battle', 'unhappy', 'bad', 'alarming', 'angry', 'anxious', 'dirty', 'pain', 'poison', 'unfair',\n",
    "              'unhealthy'\n",
    "              ], label=NEGATIVE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T01:55:37.235815Z",
     "end_time": "2023-04-14T01:55:37.298800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# set up a preprocessor function to determine polarity & subjectivity using textlob pretrained classifier\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "\n",
    "\n",
    "# find polarity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return POSITIVE if x.polarity > 0.6 else ABSTAIN\n",
    "\n",
    "\n",
    "# find subjectivity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return POSITIVE if x.subjectivity >= 0.5 else ABSTAIN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T01:55:37.259799Z",
     "end_time": "2023-04-14T01:55:37.298800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1046879/1244184 [23:34<04:17, 765.30it/s] "
     ]
    }
   ],
   "source": [
    "# combine all the labeling functions\n",
    "lfs = [keyword_positive, keyword_negative, textblob_polarity, textblob_subjectivity]\n",
    "\n",
    "# apply the lfs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_snorkel = applier.apply(df=df)\n",
    "\n",
    "# apply the label model\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "\n",
    "# fit on the data\n",
    "label_model.fit(L_snorkel)\n",
    "\n",
    "# predict and create the labels\n",
    "df[\"label\"] = label_model.predict(L=L_snorkel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T01:55:37.280816Z",
     "end_time": "2023-04-14T02:23:41.451723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 348005 entries, 1 to 1244182\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    348005 non-null  object\n",
      " 1   label   348005 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:45:55.637531Z",
     "end_time": "2023-04-14T02:45:55.791517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "1    238018\n0    109987\nName: label, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out unlabeled data points\n",
    "df = df.loc[df.label.isin([0, 1]), :]\n",
    "\n",
    "# find the label counts\n",
    "df['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:45:40.163955Z",
     "end_time": "2023-04-14T02:45:40.226953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df.to_csv(\"data_nlp.csv\", encoding='utf-8', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:47:38.156343Z",
     "end_time": "2023-04-14T02:47:39.732843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def toLower(data):\n",
    "    if isinstance(data, float):\n",
    "        return '<UNK>'\n",
    "    else:\n",
    "        return data.lower()\n",
    "\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    no_stop = []\n",
    "    for word in text.split(' '):\n",
    "        if word not in stop_words:\n",
    "            no_stop.append(word)\n",
    "    return \" \".join(no_stop)\n",
    "\n",
    "\n",
    "def remove_punctuation_func(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9]', ' ', text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:59:18.730338Z",
     "end_time": "2023-04-14T02:59:18.747327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['label']\n",
    "X = X.apply(toLower)\n",
    "X = X.apply(remove_stopwords)\n",
    "X = X.apply(lambda x: lemm.lemmatize(x))\n",
    "X = X.apply(remove_punctuation_func)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:59:19.323035Z",
     "end_time": "2023-04-14T02:59:29.259034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# preprocess\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=120, padding='post', truncating='post')\n",
    "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=120, padding='post', truncating='post')\n",
    "# convert lists into numpy arrays to make it work with TensorFlow\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(y_train)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:59:29.281029Z",
     "end_time": "2023-04-14T02:59:44.413500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                408       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=120),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:59:44.419504Z",
     "end_time": "2023-04-14T02:59:44.566207Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8157/8157 - 34s - loss: 0.2106 - accuracy: 0.9100 - val_loss: 0.0788 - val_accuracy: 0.9750 - 34s/epoch - 4ms/step\n",
      "Epoch 2/5\n",
      "8157/8157 - 28s - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.0621 - val_accuracy: 0.9811 - 28s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "8157/8157 - 32s - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0627 - val_accuracy: 0.9827 - 32s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "8157/8157 - 27s - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.0589 - val_accuracy: 0.9836 - 27s/epoch - 3ms/step\n",
      "Epoch 5/5\n",
      "8157/8157 - 27s - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.0625 - val_accuracy: 0.9801 - 27s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(training_padded,\n",
    "                    training_labels,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(testing_padded, testing_labels),\n",
    "                    verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T02:59:57.528160Z",
     "end_time": "2023-04-14T03:02:27.465901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 228ms/step\n",
      "[[0.00845004]]\n"
     ]
    }
   ],
   "source": [
    "new_headline = [\"The US imposes sanctions on Rassia because of the Ukranian war\"]\n",
    "# prepare the sequences of the sentences in question\n",
    "sequences = tokenizer.texts_to_sequences(new_headline)\n",
    "padded_seqs = pad_sequences(sequences, maxlen=120, padding='post', truncating='post')\n",
    "print(model.predict(padded_seqs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T03:02:35.314486Z",
     "end_time": "2023-04-14T03:02:35.674491Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
