{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ndim = 4\n",
    "m = tf.convert_to_tensor([2., 4., 6., 17.])\n",
    "c = tf.convert_to_tensor(-10.)\n",
    "\n",
    "def generate_batch(batch_size):\n",
    "  x = tf.random.uniform((batch_size, ndim))\n",
    "  y = tf.reduce_sum(x * m, axis=1) + c\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m_pred = tf.random.uniform((ndim,))\n",
    "c_pred = tf.random.uniform(())\n",
    "\n",
    "batch_size = 32\n",
    "num_iterations = 7000\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 500\n",
      "Iteration 1000\n",
      "Iteration 1500\n",
      "Iteration 2000\n",
      "Iteration 2500\n",
      "Iteration 3000\n",
      "Iteration 3500\n",
      "Iteration 4000\n",
      "Iteration 4500\n",
      "Iteration 5000\n",
      "Iteration 5500\n",
      "Iteration 6000\n",
      "Iteration 6500\n"
     ]
    }
   ],
   "source": [
    "loss_log = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "  if i % 500 == 0:\n",
    "    print(\"Iteration\", i)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch([m_pred, c_pred])\n",
    "    x, y = generate_batch(batch_size=32)\n",
    "    y_pred = tf.reduce_sum(x * m_pred) + c_pred\n",
    "    diffs = y - y_pred\n",
    "    mse = 1/2 * tf.reduce_mean(diffs ** 2)\n",
    "  \n",
    "    dloss_dm, dloss_dc = tape.gradient(mse, [m_pred, c_pred])\n",
    "    m_pred -= learning_rate * dloss_dm\n",
    "    c_pred -= learning_rate * dloss_dc\n",
    "    loss_log.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,4] vs. [32] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m diffs \u001B[38;5;241m=\u001B[39m y \u001B[38;5;241m-\u001B[39m y_pred\n\u001B[0;32m      7\u001B[0m mse \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_mean(diffs \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m dloss_dm \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mtf\u001B[38;5;241m.\u001B[39mreduce_mean(\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdiffs\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      9\u001B[0m dloss_dc \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mtf\u001B[38;5;241m.\u001B[39mreduce_mean(diffs)\n\u001B[0;32m     10\u001B[0m m_pred \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m learning_rate \u001B[38;5;241m*\u001B[39m dloss_dm\n",
      "File \u001B[1;32mC:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\coding\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7186\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7185\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7186\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Incompatible shapes: [32,4] vs. [32] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "loss_log = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "  x, y = generate_batch(batch_size=32)\n",
    "  y_pred = tf.reduce_sum(x * m_pred) + c_pred\n",
    "  diffs = y - y_pred\n",
    "  mse = 1/2 * tf.reduce_mean(diffs ** 2)\n",
    "  dloss_dm = -tf.reduce_mean(x * diffs, axis=0)\n",
    "  dloss_dc = -tf.reduce_mean(diffs)\n",
    "  m_pred -= learning_rate * dloss_dm\n",
    "  c_pred -= learning_rate * dloss_dc\n",
    "  loss_log.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m_pred, c_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TensorFlow model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "n_examples = 32768\n",
    "ndim = 100\n",
    "\n",
    "weights = tf.random.uniform((ndim,), minval=-10, maxval=10)\n",
    "bias = tf.random.uniform((), minval=-10, maxval=10)\n",
    "train_x = tf.random.normal((n_examples, ndim))\n",
    "train_y = tf.reduce_sum(train_x * weights, axis=1) + bias\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.InputLayer((ndim,)),\n",
    "  layers.Dense(1, activation=None),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.fit(x=train_x, y=train_y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_x = tf.random.normal((1, ndim))\n",
    "test_y = tf.reduce_sum(test_x * weights, axis=1) + bias\n",
    "\n",
    "print(\"Model prediction:\", model.predict(test_x))\n",
    "print(\"True y-value:\", test_y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "945ea36e656d6aa26ebe4bdd7128e099cc0e42d2c2118248527baa71decc73b8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}